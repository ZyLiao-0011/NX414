{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e72586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from utils import load_it_data, visualize_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdown\n",
    "\n",
    "DOWNLOAD = False\n",
    "\n",
    "if DOWNLOAD:\n",
    "    url = \"https://drive.google.com/file/d/1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS/view?usp=share_link\"\n",
    "    output = \"IT_data.h5\"\n",
    "    gdown.download(url, output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ccf24",
   "metadata": {},
   "source": [
    "## 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3be57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '' \n",
    "stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val = load_it_data(path_to_data)\n",
    "\n",
    "n_stimulus, n_channels, img_size, _ = stimulus_train.shape\n",
    "_, n_neurons = spikes_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1433d",
   "metadata": {},
   "source": [
    "## 1. Prediction from pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74345a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2592, 1000), (288, 1000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import cross_validate,KFold\n",
    "\n",
    "X_train = stimulus_train.reshape(stimulus_train.shape[0], -1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val = stimulus_val.reshape(stimulus_val.shape[0], -1)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "\n",
    "pca = PCA(n_components=1000)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "X_train_pca.shape,X_val_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6da700",
   "metadata": {},
   "source": [
    "### 1.1 Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1329d9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Pearson correlation:  0.221168866209307\n",
      "Explained variance:  -0.0724655691356886\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_pca, spikes_train)\n",
    "\n",
    "pearson_corr_lr = np.zeros(n_neurons)\n",
    "predictions_val_lr = lr.predict(X_val_pca)\n",
    "for i in range(n_neurons):\n",
    "    pearson_corr_lr[i] = np.corrcoef(predictions_val_lr[:, i], spikes_val[:, i])[0, 1]\n",
    "explained_var_lr = explained_variance_score(spikes_val, predictions_val_lr, multioutput='raw_values')\n",
    "\n",
    "print(\"Linear Regression\")\n",
    "print(\"Pearson correlation: \", np.mean(pearson_corr_lr))\n",
    "print(\"Explained variance: \", np.mean(explained_var_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339e7e1",
   "metadata": {},
   "source": [
    "### 1.2 Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_alpha_ridge(X, y, candidate_alphas=None, n_splits=5, scoring='explained_variance'):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation to find the best alpha for Ridge regression.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): Input features of shape (n_samples, n_features)\n",
    "        y (np.ndarray): Target values of shape (n_samples, n_targets)\n",
    "        candidate_alphas (list): List of alpha values to try\n",
    "        n_splits (int): Number of cross-validation folds\n",
    "        scoring (str): Metric to use ('explained_variance' or 'correlation')\n",
    "\n",
    "    Returns:\n",
    "        float: Best alpha value\n",
    "    \"\"\"\n",
    "    if candidate_alphas is None:\n",
    "        candidate_alphas = np.logspace(-2,5,5)\n",
    "\n",
    "    best_alpha = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for alpha in candidate_alphas:\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=888)\n",
    "        fold_scores = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_tr, X_val = X[train_idx], X[val_idx]\n",
    "            y_tr, y_val_cv = y[train_idx], y[val_idx]\n",
    "\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(X_tr, y_tr)\n",
    "            preds = model.predict(X_val)\n",
    "\n",
    "            if scoring == 'explained_variance':\n",
    "                score = np.mean([\n",
    "                    explained_variance_score(y_val_cv[:, n], preds[:, n])\n",
    "                    for n in range(y.shape[1])\n",
    "                ])\n",
    "            elif scoring == 'correlation':\n",
    "                score = np.mean([\n",
    "                    np.corrcoef(preds[:, n], y_val_cv[:, n])[0, 1]\n",
    "                    for n in range(y.shape[1])\n",
    "                ])\n",
    "            else:\n",
    "                raise ValueError(\"Invalid scoring. Use 'explained_variance' or 'correlation'.\")\n",
    "\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(fold_scores)\n",
    "        print(f\"Alpha {alpha:.1e} -> CV {scoring}: {avg_score:.4f}\")\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_alpha = alpha\n",
    "\n",
    "    print(f\"✅ Best alpha: {best_alpha:.1e} with CV {scoring}: {best_score:.4f}\")\n",
    "    return best_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f3d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 1.0e-02 -> CV explained_variance: -1.3631\n",
      "Alpha 5.6e-01 -> CV explained_variance: -1.3627\n",
      "Alpha 3.2e+01 -> CV explained_variance: -1.3410\n",
      "Alpha 1.8e+03 -> CV explained_variance: -0.7186\n",
      "Alpha 1.0e+05 -> CV explained_variance: 0.0600\n",
      "✅ Best alpha: 1.0e+05 with CV explained_variance: 0.0600\n",
      "Ridge Regression\n",
      "Pearson correlation:  0.2739008283023446\n",
      "Explained variance:  0.08147349208593369\n"
     ]
    }
   ],
   "source": [
    "best_alpha = find_best_alpha_ridge(X_train_pca, spikes_train, candidate_alphas=None, n_splits=5, scoring='explained_variance')\n",
    "ridge = Ridge(alpha=best_alpha)\n",
    "ridge.fit(X_train_pca, spikes_train)\n",
    "predictions_val_ridge = ridge.predict(X_val_pca)\n",
    "pearson_corr_ridge = np.zeros(n_neurons)\n",
    "for i in range(n_neurons):\n",
    "    pearson_corr_ridge[i] = np.corrcoef(predictions_val_ridge[:, i], spikes_val[:, i])[0, 1]\n",
    "explained_var_ridge = explained_variance_score(spikes_val, predictions_val_ridge, multioutput='raw_values')\n",
    "print(\"Ridge Regression\")\n",
    "print(\"Pearson correlation: \", np.mean(pearson_corr_ridge))\n",
    "print(\"Explained variance: \", np.mean(explained_var_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24932348",
   "metadata": {},
   "source": [
    "### 1.3 Brief conclusion\n",
    "Ridge regression performs slightly better than naive linear regression. Hence we established our regression model: after extracting first 1000 PCs, then perform Ridge regression with the best alpha value found by grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32536b20",
   "metadata": {},
   "source": [
    "## 2. Task-driven approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef11914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pickle\n",
    "from torch.nn import init\n",
    "from torch.nn import Parameter\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "y_train = spikes_train\n",
    "y_val = spikes_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA available: Yes\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA available: No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8035eaf",
   "metadata": {},
   "source": [
    "### 2.1 Define functions to extract layer activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa86252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model, layers):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.model = model\n",
    "        self.layers = layers\n",
    "        self._features = {layer: torch.empty(0) for layer in layers}\n",
    "\n",
    "        for layer_id in layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_id]\n",
    "            layer.register_forward_hook(self.get_hook(layer_id))\n",
    "\n",
    "    def get_hook(self, layer_id):\n",
    "        def hook(module, input, output):\n",
    "            self._features[layer_id] = output\n",
    "        return hook\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model(x)\n",
    "        return [self._features[layer_id] for layer_id in self.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HxWxC numpy images to CxHxW torch tensors\n",
    "def preprocess_images(images):\n",
    "    # Images are already normalized in the dataset\n",
    "    # Convert to torch tensor and adjust dimensions\n",
    "    images_tensor = torch.tensor(images, dtype=torch.float32)\n",
    "    # Our images are already in the format [batch, channels, height, width]\n",
    "    return images_tensor\n",
    "def extract_features(model, stimulus, batch_size=128):\n",
    "    # Create feature extractor\n",
    "    extractor = FeatureExtractor(model, layers_to_extract)\n",
    "    extractor.to(device)\n",
    "    extractor.eval()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Process one layer at a time\n",
    "    for layer_name in layers_to_extract:\n",
    "        print(f\"\\nProcessing layer: {layer_name}\")\n",
    "\n",
    "        # Create DataLoader\n",
    "        dataset = TensorDataset(preprocess_images(stimulus))\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Collect activations\n",
    "        layer_activations = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=f\"Extracting {layer_name}\"):\n",
    "                batch = batch[0].to(device)\n",
    "                # Call the entire model to get all activations\n",
    "                activations = extractor(batch)\n",
    "                # Find the index of the current layer\n",
    "                layer_idx = layers_to_extract.index(layer_name)\n",
    "                # Get activations for the current layer\n",
    "                layer_act = activations[layer_idx].cpu().numpy()\n",
    "\n",
    "                # Flatten\n",
    "                if len(layer_act.shape) > 2:\n",
    "                    if layer_name == 'avgpool':\n",
    "                        layer_act = layer_act.reshape(layer_act.shape[0], -1)\n",
    "                    else:\n",
    "                        layer_act = layer_act.reshape(layer_act.shape[0], -1)\n",
    "\n",
    "                layer_activations.append(layer_act)\n",
    "\n",
    "        # Combine batches\n",
    "        layer_act = np.vstack(layer_activations)\n",
    "\n",
    "        # Store original features\n",
    "        results[layer_name] = {\n",
    "            'features': layer_act\n",
    "        }\n",
    "\n",
    "        # ===============\n",
    "        # clean up memory\n",
    "        del layer_activations, layer_act\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Clean up extractor\n",
    "    del extractor\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return results\n",
    "\n",
    "def apply_pca_to_features(train_features, val_features, n_components=1000):\n",
    "    train_pcs = {}\n",
    "    val_pcs = {}\n",
    "\n",
    "    for layer_name in layers_to_extract:\n",
    "        X_train = train_features[layer_name]['features']\n",
    "        X_val = val_features[layer_name]['features']\n",
    "\n",
    "        # If n_components is greater than or equal to the feature dimensions, skip PCA\n",
    "        if n_components >= X_train.shape[1]:\n",
    "            print(f\"Layer {layer_name}: Skipping PCA as n_components ({n_components}) >= feature dimensions ({X_train.shape[1]})\")\n",
    "            train_pcs[layer_name] = {\n",
    "                'pcs': X_train,\n",
    "                'scaler': None,\n",
    "                'pca': None\n",
    "            }\n",
    "            val_pcs[layer_name] = {\n",
    "                'pcs': X_val\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)  # 使用相同的scaler\n",
    "\n",
    "        n_comp = min(n_components, X_train.shape[0], X_train.shape[1])\n",
    "        pca = PCA(n_components=n_comp)\n",
    "        train_pcs[layer_name] = {\n",
    "            'pcs': pca.fit_transform(X_train_scaled),\n",
    "            'scaler': scaler,\n",
    "            'pca': pca\n",
    "        }\n",
    "\n",
    "        val_pcs[layer_name] = {\n",
    "            'pcs': pca.transform(X_val_scaled)\n",
    "        }\n",
    "\n",
    "        print(f\"Layer {layer_name}: {n_comp} components, {sum(pca.explained_variance_ratio_):.4f} variance explained\")\n",
    "\n",
    "    return train_pcs, val_pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8309d4a",
   "metadata": {},
   "source": [
    "### 2.2 Initialize pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00750045",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_extract_pca = \"True\"\n",
    "# What model you want to use?\n",
    "# mobilenet, vgg16, alexnet, resnet18, resnet50, vit or random for unpretrained model\n",
    "my_model = \"resnet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20dcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Model Selection Block (MobileNetV2, VGG16, AlexNet, DenseNet121, ResNet18, ViT)\n",
    "# =============================\n",
    "from torchvision.models import (\n",
    "    mobilenet_v2, vgg16, alexnet, densenet121,\n",
    "    resnet18, vit_b_16,resnet50\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if my_model == \"mobilenet\":\n",
    "    print(\"Using MobileNetV2 pretrained model\")\n",
    "    pretrained_model = mobilenet_v2(pretrained=True)\n",
    "    pretrained_model.to(device)\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    layers_to_extract = [\n",
    "        'features.0',\n",
    "        'features.3',\n",
    "        'features.6',\n",
    "        'features.10',\n",
    "        'features.14',\n",
    "        'features.18',\n",
    "    ]\n",
    "\n",
    "elif my_model == \"vgg16\":\n",
    "    print(\"Using VGG16 pretrained model\")\n",
    "    pretrained_model = vgg16(pretrained=True)\n",
    "    pretrained_model.to(device)\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    layers_to_extract = [\n",
    "        'features.4',\n",
    "        'features.9',\n",
    "        'features.16',  \n",
    "        'features.23',  \n",
    "        'features.30'  \n",
    "    ]\n",
    "\n",
    "elif my_model == \"alexnet\":\n",
    "    print(\"Using AlexNet pretrained model\")\n",
    "    pretrained_model = alexnet(pretrained=True)\n",
    "    pretrained_model.to(device)\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    layers_to_extract = [\n",
    "        'features.0',   # conv1\n",
    "        'features.2',\n",
    "        'features.5',\n",
    "        'features.12'\n",
    "    ]\n",
    "\n",
    "\n",
    "elif my_model == \"resnet18\":\n",
    "    print(\"Using ResNet18 pretrained model\")\n",
    "    pretrained_model = resnet18(pretrained=True)\n",
    "    pretrained_model.to(device)\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    layers_to_extract = [\n",
    "        'conv1',\n",
    "        'layer1',\n",
    "        'layer2',\n",
    "        'layer3',\n",
    "        'layer4',\n",
    "    ]\n",
    "\n",
    "elif my_model == \"resnet50\":\n",
    "    print(\"Using ResNet50 pretrained model\")\n",
    "    pretrained_model = resnet50(pretrained=True)\n",
    "    pretrained_model.to(device)\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    layers_to_extract = [\n",
    "        'conv1',\n",
    "        'layer1',\n",
    "        'layer2',\n",
    "        'layer3',\n",
    "        'layer4',\n",
    "    ]\n",
    "\n",
    "elif my_model == \"vit\":\n",
    "    print(\"Using Vision Transformer (ViT-B/16) pretrained model\")\n",
    "    pretrained_model = vit_b_16(pretrained=True)\n",
    "    pretrained_model.to(device)\n",
    "    pretrained_model.eval()\n",
    "\n",
    "    # ViT has a flat structure, so just one key representation layer\n",
    "    layers_to_extract = [\n",
    "        'conv_proj',\n",
    "        'encoder',\n",
    "        'heads',\n",
    "    ]\n",
    "    \n",
    "elif my_model == \"random\":\n",
    "    print(\"Using Randomly Initialized Model\")\n",
    "    random_model = resnet50(pretrained=False)\n",
    "    random_model.to(device)\n",
    "    random_model.eval()\n",
    "    layers_to_extract = [\n",
    "        'conv1',\n",
    "        'layer1',\n",
    "        'layer2',\n",
    "        'layer3',\n",
    "        'layer4',\n",
    "    ]\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model type. Choose from: 'pretrained', 'vgg16', 'alexnet', 'densenet', 'resnet', 'vit'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cae291",
   "metadata": {},
   "source": [
    "### 2.3 (Optional) Fine-tune pretrained Model\n",
    "Use pretrained ResNet50 to fine-tune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50617c97",
   "metadata": {},
   "source": [
    "#### 2.3.1 Preparation\n",
    "Encode fine-tuning labels，get the pretrained model and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of the labels\n",
    "y_ft_train = objects_train\n",
    "y_ft_val = objects_val\n",
    "unique_classes = sorted(list(set(y_ft_train) | set(y_ft_val)))\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "y_ft_train = np.array([class_to_idx[cls] for cls in objects_train])\n",
    "y_ft_val = np.array([class_to_idx[cls] for cls in objects_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8640726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet50\"\n",
    "resnet50 = getattr(models, model_name)(weights='IMAGENET1K_V1')\n",
    "num_features = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_features, num_classes)  \n",
    "\n",
    "resnet50.eval()  # Set to evaluation mode\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Create training dataset and dataloader\n",
    "train_dataset = TensorDataset(\n",
    "    preprocess_images(stimulus_train), \n",
    "    torch.tensor(y_ft_train, dtype=torch.long)\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create evaluation dataset and dataloader\n",
    "eval_dataset = TensorDataset(\n",
    "    preprocess_images(stimulus_val), \n",
    "    torch.tensor(y_ft_val, dtype=torch.long)\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797799f",
   "metadata": {},
   "source": [
    "### 2.3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, eval_dataloader, y_train, y_val, criterion,\n",
    "                num_epochs, device, warmup_epochs=2, lr_start=0.001, lr_max=0.01, lr_min=0.000001,\n",
    "                patience=50, min_delta=0.001):\n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Initialize optimizer with starting learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_start)\n",
    "    \n",
    "    # Use a more aggressive learning rate scheduler\n",
    "    # ReduceLROnPlateau reduces LR when a metric has stopped improving\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',\n",
    "        factor=0.5,     # Reduce LR by half when triggered\n",
    "        patience=5,     # Number of epochs with no improvement after which LR will be reduced\n",
    "        min_lr=lr_min\n",
    "    )\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_mse = float('inf')\n",
    "    counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            total_mse = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for inputs, targets in eval_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Calculate MSE\n",
    "                batch_mse = criterion(outputs, targets).item()\n",
    "                total_mse += batch_mse\n",
    "                num_batches += 1\n",
    "                \n",
    "                # Store predictions for further analysis if needed\n",
    "                all_preds.append(outputs.cpu().numpy())\n",
    "                \n",
    "        # Calculate average MSE over all validation batches\n",
    "        val_mse = total_mse / num_batches\n",
    "        val_accuracies.append(-val_mse)  # Store negative MSE so higher is better in plots\n",
    "        \n",
    "        # Step the scheduler based on validation loss\n",
    "        scheduler.step(val_mse)\n",
    "        \n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, LR: {current_lr:.6f}, Loss: {epoch_loss:.4f}, Validation MSE: {val_mse:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_mse < best_val_mse - min_delta:\n",
    "            best_val_mse = val_mse\n",
    "            counter = 0\n",
    "            # Save the best model state\n",
    "            best_model_state = {k: v.cpu().detach().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                # Load the best model state\n",
    "                if best_model_state is not None:\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    \n",
    "    return train_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 1000\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model=resnet50,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    y_train=y_ft_train,\n",
    "    y_val=y_ft_val,\n",
    "    criterion=criterion,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "filename = \"resnet50_fpft_classification.pth\" \n",
    "print(\"Selected model name is \", filename)\n",
    "torch.save(resnet50.state_dict(), filename)\n",
    "print(f\"Model saved successfully to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfa4dc",
   "metadata": {},
   "source": [
    "#### 2.3.3 Load fine-tuned model if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fde1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "filename = \"resnet50_fpft_classification.pth\"\n",
    "pretrained_model = resnet50(pretrained = False)\n",
    "pretrained_model.fc = nn.Linear(num_features, num_classes)\n",
    "pretrained_model.load_state_dict(torch.load(filename))\n",
    "pretrained_model.to(device)\n",
    "pretrained_model.eval()  # Set the model to evaluation mode\n",
    "print(f\"Model loaded successfully from '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bb7f4",
   "metadata": {},
   "source": [
    "### 2.4 Obtain activation and perform PCA per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_to_extract_pca==\"True\":\n",
    "    if my_model != \"random\":\n",
    "        print(\"Extracting features from pre-trained model...\")\n",
    "        pretrained_features_train = extract_features(pretrained_model, stimulus_train, batch_size=64)\n",
    "        pretrained_features_val = extract_features(pretrained_model, stimulus_val, batch_size=64)\n",
    "    else:\n",
    "        print(\"Extracting features from randomly initialized model...\")\n",
    "        random_features_train = extract_features(random_model, stimulus_train)\n",
    "        random_features_val = extract_features(random_model, stimulus_val)\n",
    "else:\n",
    "    print(\"No need to extract features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_to_extract_pca == \"True\":\n",
    "    print(f\"Extracting PCA from {my_model} model...\")\n",
    "    #if my_model == \"pretrained\":\n",
    "    if my_model != \"random\":\n",
    "        pretrained_pcs_train, pretrained_pcs_val = apply_pca_to_features(\n",
    "            pretrained_features_train,\n",
    "            pretrained_features_val,\n",
    "            n_components=1000\n",
    "        )\n",
    "    else:\n",
    "        random_pcs_train, random_pcs_val = apply_pca_to_features(\n",
    "            random_features_train,\n",
    "            random_features_val,\n",
    "            n_components=1000\n",
    "        )\n",
    "else:\n",
    "    print(\"No need to extract PCA from features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_neural_activity(layer_pcs_train, layer_pcs_val, y_train, y_val, sample_to_plot=0):\n",
    "    layer_metrics = {}\n",
    "    sample_predictions = {}\n",
    "\n",
    "    for layer_name in layers_to_extract:\n",
    "        print(f\"Predicting neural activity using {layer_name}\")\n",
    "        X_train_pcs = layer_pcs_train[layer_name]['pcs']\n",
    "        X_val_pcs = layer_pcs_val[layer_name]['pcs']\n",
    "\n",
    "\n",
    "        if X_train_pcs.shape[1] != X_val_pcs.shape[1]:\n",
    "            print(f\"Warning: Feature mismatch for {layer_name}. Training: {X_train_pcs.shape[1]}, Validation: {X_val_pcs.shape[1]}\")\n",
    "            min_components = min(X_train_pcs.shape[1], X_val_pcs.shape[1])\n",
    "            X_train_pcs = X_train_pcs[:, :min_components]\n",
    "            X_val_pcs = X_val_pcs[:, :min_components]\n",
    "            print(f\"Using {min_components} components for both sets\")\n",
    "\n",
    "        correlations = []\n",
    "        exp_variances = []\n",
    "        sample_neuron_predictions = []  # Store predictions for all neurons for a specific sample\n",
    "\n",
    "        best_alpha = find_best_alpha_ridge(X_train_pcs, y_train, candidate_alphas=np.logspace(-2,5,10), n_splits=5, scoring='explained_variance')\n",
    "        lr = Ridge(alpha=best_alpha)\n",
    "        lr.fit(X_train_pcs, y_train)\n",
    "\n",
    "        y_pred = lr.predict(X_val_pcs)\n",
    "        y_true = y_val\n",
    "\n",
    "            # Calculate correlation and explained variance\n",
    "        for neuron in tqdm(range(y_train.shape[1]), desc=f\"Training models for {layer_name}\"):\n",
    "            correlation = np.corrcoef(y_pred[:,neuron], y_true[:,neuron])[0, 1]\n",
    "            exp_var = explained_variance_score(y_true[:,neuron], y_pred[:,neuron])\n",
    "\n",
    "            correlations.append(correlation)\n",
    "            exp_variances.append(exp_var)\n",
    "\n",
    "            # Save prediction for the specific sample\n",
    "            sample_neuron_predictions.append(y_pred[sample_to_plot,neuron])\n",
    "\n",
    "        layer_metrics[layer_name] = {\n",
    "            'correlations': correlations,\n",
    "            'exp_variances': exp_variances,\n",
    "            'mean_correlation': np.mean(correlations),\n",
    "            'mean_exp_variance': np.mean(exp_variances)\n",
    "        }\n",
    "\n",
    "        sample_predictions[layer_name] = np.array(sample_neuron_predictions)\n",
    "\n",
    "        print(f\"Mean correlation for {layer_name}: {np.mean(correlations):.4f}\")\n",
    "        print(f\"Mean explained variance for {layer_name}: {np.mean(exp_variances):.4f}\")\n",
    "\n",
    "\n",
    "    # PLOT a single case just to visualize... not that meaningful tho\n",
    "\n",
    "    # Plot predictions for all neurons from each layer for a specific sample\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    neurons = np.arange(y_val.shape[1])\n",
    "    plt.plot(neurons, y_val[sample_to_plot], 'ko-', label='True Activity', linewidth=2)\n",
    "\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(layers_to_extract)))\n",
    "    for i, layer_name in enumerate(layers_to_extract):\n",
    "        plt.plot(neurons, sample_predictions[layer_name], 'o-', color=colors[i], label=f'{layer_name} Prediction', alpha=0.8)\n",
    "\n",
    "    plt.title(f'Neural Activity Predictions for Sample {sample_to_plot}')\n",
    "    plt.xlabel('Neuron Number')\n",
    "    plt.ylabel('Neural Activity')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('all_layer_predictions.png')\n",
    "    plt.show()\n",
    "\n",
    "    return layer_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86149fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if my_model == \"pretrained\":\n",
    "if my_model != \"random\":\n",
    "    print(\"Predicting with pre-trained model features...\")\n",
    "    layer_metrics = predict_neural_activity(pretrained_pcs_train, pretrained_pcs_val, y_train, y_val)\n",
    "else:\n",
    "    print(\"Predicting with randomly initialized model features...\")\n",
    "    layer_metrics = predict_neural_activity(random_pcs_train, random_pcs_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"layer_metrics.json\"\n",
    "# Define a custom encoder for NumPy types\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.generic):\n",
    "            return obj.item()\n",
    "        return super().default(obj)\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(layer_metrics, f, cls=NumpyEncoder, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca753766",
   "metadata": {},
   "source": [
    "## 3. Data-driven aproach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9aab3e",
   "metadata": {},
   "source": [
    "### 3.1 Define dataloader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ba2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeData(Dataset):\n",
    "    def __init__(self,stimulus,spike = None):\n",
    "        self.stimulus = torch.tensor(stimulus)\n",
    "\n",
    "        if spike is not None:\n",
    "          self.spike = torch.tensor(spike)\n",
    "          self.num_neuron = self.spike.shape[1]\n",
    "        else:\n",
    "          self.spike = None\n",
    "          self.num_neuron = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stimulus)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.spike is not None:\n",
    "            return self.stimulus[idx], self.spike[idx]\n",
    "        else:\n",
    "            return self.stimulus[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af898289",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITdataloader_train = DataLoader(SpikeData(stimulus_train, spikes_train), batch_size=64, shuffle=True)\n",
    "ITdataloader_val = DataLoader(SpikeData(stimulus_val, spikes_val), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1524b9",
   "metadata": {},
   "source": [
    "### 3.2. Build shallow CNN for strike prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c49943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowCNN(nn.Module):\n",
    "    def __init__(self,num_neuron):\n",
    "        super(ShallowCNN, self).__init__()\n",
    "\n",
    "        # Conv block 1\n",
    "        self.convblock1 = nn.Sequential(nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.BatchNorm2d(16),\n",
    "                                        nn.ReLU6(),\n",
    "                                        nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        # Conv block 2\n",
    "        self.convblock2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.BatchNorm2d(32),\n",
    "                                        nn.ReLU6(),\n",
    "                                        nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        # Conv block 3\n",
    "        self.convblock3 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                        nn.BatchNorm2d(64),\n",
    "                                        nn.ReLU6(),\n",
    "                                        nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        # Adaptive flatten to work for 224x224 input images\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Calculate the size of the feature map after conv blocks\n",
    "        # For 224x224 input -> 112 -> 56 -> 28 after 3 maxpools\n",
    "        conv_output_size = 64 * (224 // 8) * (224 // 8)  # 64 channels, 28x28 feature map\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_output_size, 64)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, num_neuron)  # Output = num_neuron = 168\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod \n",
    "    @torch.no_grad() \n",
    "    def init_weights(module):\n",
    "        # He initialization\n",
    "        # Conv2d layers\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        # Linear layers\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "        # Initialize BatchNorm weights to 1 and bias to 0\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyMobilenet(nn.Module):\n",
    "    def __init__(self, num_neuron):\n",
    "        super(ToyMobilenet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Initial Convolutional Block 1\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Convolutional Block 2\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Convolutional Block 3\n",
    "            nn.Conv2d(16, 32, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            # First Inverted Residual Block\n",
    "            nn.Conv2d(32, 64, kernel_size=1, bias=False),  # Expansion\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64, bias=False),  # Depthwise Conv\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=1, bias=False),  # Projection\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            # Convolutional Block 4 (downsampling to 16x16)\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Convolutional Block 5\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            # Convolutional Block 6\n",
    "            nn.Conv2d(128, 128, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            # Second Inverted Residual Block\n",
    "            nn.Conv2d(128, 256, kernel_size=1, bias=False),  # Expansion\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, groups=256, bias=False),  # Depthwise Conv\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=1, bias=False),  # Projection\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            # Final Expansion and Projection Layer\n",
    "            nn.Conv2d(128, 64, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((2, 2)),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 2 * 2, num_neuron)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    @staticmethod # defines that the following function does not take self as input\n",
    "    @torch.no_grad()\n",
    "    def init_weights(module):\n",
    "        # He initialization\n",
    "        # Conv2d layers\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        # Linear layers\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "        # Initialize BatchNorm weights to 1 and bias to 0\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57ebb1",
   "metadata": {},
   "source": [
    "### 3.3. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2, scheduler=None):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "            for stimulus, spikes in train_loader:\n",
    "                stimulus, spikes = stimulus.to(device), spikes.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(stimulus)\n",
    "                loss = criterion(outputs, spikes)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                pbar.set_postfix(loss=running_loss / (pbar.n + 1))\n",
    "                pbar.update(1)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for stimulus, labels in val_loader:\n",
    "                stimulus, labels = stimulus.to(device), labels.to(device)\n",
    "                outputs = model(stimulus)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76168927",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "my_model = \"shallowcnn\" # or toymobilenet\n",
    "if my_model == \"shallowcnn\":\n",
    "    model = ShallowCNN(num_neuron=n_neurons)\n",
    "    model.apply(ShallowCNN.init_weights)\n",
    "elif my_model == \"toymobilenet\":\n",
    "    model = ToyMobilenet(num_neuron=n_neurons)\n",
    "    model.apply(ToyMobilenet.init_weights)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported model type. Choose from: 'shallowcnn', 'toymobilenet'\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.005, weight_decay=1e-5)\n",
    "if my_model == \"toymobilenet\":\n",
    "    scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.1, patience=5)\n",
    "else:\n",
    "    scheduler = None\n",
    "train_model(model, ITdataloader_train, ITdataloader_val, loss_fn, optimizer, num_epochs=60, scheduler=scheduler)\n",
    "\n",
    "if my_model == \"shallowcnn\":\n",
    "    save_path = 'shallow_cnn.pth'\n",
    "elif my_model == \"toymobilenet\":\n",
    "    save_path = 'toy_mobilenet.pth'\n",
    "    \n",
    "\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f8ccf",
   "metadata": {},
   "source": [
    "### 3.4. Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91facdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "load_path = 'shallow_cnn.pth'\n",
    "my_model = \"shallowcnn\" # or toymobilenet\n",
    "\n",
    "if load:\n",
    "    if my_model == \"shallowcnn\":\n",
    "        model = ShallowCNN(num_neuron=n_neurons)\n",
    "    elif my_model == \"toymobilenet\":\n",
    "        model = ToyMobilenet(num_neuron=n_neurons)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657eedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "prediction_train = []\n",
    "\n",
    "ITdataloader_train2 = DataLoader(SpikeData(stimulus_train, spikes_train), batch_size=64, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for stimulus, _ in ITdataloader_train2:\n",
    "        inputs = stimulus.to(device)\n",
    "        outputs = model(inputs)\n",
    "        prediction_train.append(outputs.cpu())\n",
    "\n",
    "prediction_train = torch.cat(prediction_train, dim=0)\n",
    "\n",
    "\n",
    "prediction_val = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for stimulus, _ in ITdataloader_val:\n",
    "        inputs = stimulus.to(device)\n",
    "        outputs = model(inputs)\n",
    "        prediction_val.append(outputs.cpu())\n",
    "\n",
    "prediction_val = torch.cat(prediction_val, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8795f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr_dd = np.zeros(n_neurons)\n",
    "for i in range(n_neurons):\n",
    "    pearson_corr_dd[i] = np.corrcoef(prediction_val[:, i], spikes_val[:, i])[0, 1]\n",
    "explained_var_dd = explained_variance_score(spikes_val, prediction_val, multioutput='raw_values')\n",
    "print(f\"Data-driven model: {my_model}\")\n",
    "print(\"Pearson correlation: \", np.mean(pearson_corr_dd))\n",
    "print(\"Explained variance: \", np.mean(explained_var_dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e34a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_metrics = {\n",
    "    'correlations': pearson_corr_dd,\n",
    "    'exp_variances': explained_var_dd,\n",
    "    'mean_correlation': np.mean(pearson_corr_dd),\n",
    "    'mean_exp_variance': np.mean(explained_var_dd)\n",
    "}\n",
    "\n",
    "filename = \"dd_metrics.json\"\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(dd_metrics, f, cls=NumpyEncoder, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19426739",
   "metadata": {},
   "source": [
    "## 4. Hybrid Method\n",
    "Use pretrained ResNet50 to predict neural activity directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92493c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet50\"\n",
    "resnet50 = getattr(models, model_name)(weights='IMAGENET1K_V1')\n",
    "\n",
    "num_features = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_features, n_neurons)  \n",
    "\n",
    "resnet50.eval()  # Set to evaluation mode\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43826509",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Create training dataset and dataloader\n",
    "train_dataset = TensorDataset(\n",
    "    preprocess_images(stimulus_train), \n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create evaluation dataset and dataloader\n",
    "eval_dataset = TensorDataset(\n",
    "    preprocess_images(stimulus_val), \n",
    "    torch.tensor(y_val, dtype=torch.float32)\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, eval_dataloader, y_train, y_val, criterion,\n",
    "                num_epochs, device, warmup_epochs=2, lr_start=0.001, lr_max=0.01, lr_min=0.000001,\n",
    "                patience=50, min_delta=0.001):\n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Initialize optimizer with starting learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_start)\n",
    "    \n",
    "    # Use a more aggressive learning rate scheduler\n",
    "    # ReduceLROnPlateau reduces LR when a metric has stopped improving\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',\n",
    "        factor=0.5,     # Reduce LR by half when triggered\n",
    "        patience=5,     # Number of epochs with no improvement after which LR will be reduced\n",
    "        min_lr=lr_min\n",
    "    )\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_mse = float('inf')\n",
    "    counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            total_mse = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for inputs, targets in eval_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Calculate MSE\n",
    "                batch_mse = criterion(outputs, targets).item()\n",
    "                total_mse += batch_mse\n",
    "                num_batches += 1\n",
    "                \n",
    "                # Store predictions for further analysis if needed\n",
    "                all_preds.append(outputs.cpu().numpy())\n",
    "                \n",
    "        # Calculate average MSE over all validation batches\n",
    "        val_mse = total_mse / num_batches\n",
    "        val_accuracies.append(-val_mse)  # Store negative MSE so higher is better in plots\n",
    "        \n",
    "        # Step the scheduler based on validation loss\n",
    "        scheduler.step(val_mse)\n",
    "        \n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, LR: {current_lr:.6f}, Loss: {epoch_loss:.4f}, Validation MSE: {val_mse:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_mse < best_val_mse - min_delta:\n",
    "            best_val_mse = val_mse\n",
    "            counter = 0\n",
    "            # Save the best model state\n",
    "            best_model_state = {k: v.cpu().detach().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                # Load the best model state\n",
    "                if best_model_state is not None:\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    \n",
    "    return train_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "num_epochs = 1000\n",
    "\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model=resnet50,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    "    criterion=criterion,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    patience=20\n",
    ")\n",
    "\n",
    "filename = \"resnet50_fpft_spike.pth\"\n",
    "torch.save(resnet50.state_dict(), filename)\n",
    "print(f\"Model saved successfully to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "resnet50.load_state_dict(torch.load(filename))\n",
    "resnet50.eval()  # Set the model to evaluation mode\n",
    "print(f\"Model loaded successfully from '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba41a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_dataloader, y_val, device):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            if isinstance(batch, list):\n",
    "                # If it's a list, assume the first element is the input\n",
    "                inputs = batch[0]\n",
    "            elif isinstance(batch, tuple):\n",
    "                inputs = batch[0]\n",
    "            else:\n",
    "                inputs = batch\n",
    "            \n",
    "            if not isinstance(inputs, torch.Tensor):\n",
    "                inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "                \n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "    \n",
    "    predictions = np.vstack(all_predictions)\n",
    "    \n",
    "    # Ensure predictions and ground truth have the same number of samples\n",
    "    if predictions.shape[0] > y_val.shape[0]:\n",
    "        predictions = predictions[:y_val.shape[0]]\n",
    "    elif predictions.shape[0] < y_val.shape[0]:\n",
    "        y_val = y_val[:predictions.shape[0]]\n",
    "    \n",
    "    # Calculate correlation and explained variance for each neuron\n",
    "    correlations = []\n",
    "    exp_variances = []\n",
    "    \n",
    "    for neuron in range(y_val.shape[1]):\n",
    "        y_true = y_val[:, neuron]\n",
    "        y_pred = predictions[:, neuron]\n",
    "        \n",
    "        # Calculate correlation\n",
    "        correlation = np.corrcoef(y_pred, y_true)[0, 1]\n",
    "        correlations.append(correlation)\n",
    "        \n",
    "        # Calculate explained variance\n",
    "        exp_var = explained_variance_score(y_true, y_pred)\n",
    "        exp_variances.append(exp_var)\n",
    "    \n",
    "    # Calculate averages and standard deviations\n",
    "    mean_correlation = np.mean(correlations)\n",
    "    std_correlation = np.std(correlations)\n",
    "    mean_exp_variance = np.mean(exp_variances)\n",
    "    std_exp_variance = np.std(exp_variances)\n",
    "    \n",
    "    print(f\"Mean Correlation: {mean_correlation:.4f} ± {std_correlation:.4f}\")\n",
    "    print(f\"Mean Explained Variance: {mean_exp_variance:.4f} ± {std_exp_variance:.4f}\")\n",
    "    \n",
    "    # Visualize overall results\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Plot correlations without sorting\n",
    "    plt.plot(range(len(correlations)), correlations, 'o-', markersize=3)\n",
    "    plt.axhline(mean_correlation, color='r', linestyle='--')\n",
    "    plt.title(f'Correlation Distribution (Mean: {mean_correlation:.4f})')\n",
    "    plt.xlabel('Neuron Index')\n",
    "    plt.ylabel('Correlation')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Plot explained variances without sorting\n",
    "    plt.plot(range(len(exp_variances)), exp_variances, 'o-', markersize=3)\n",
    "    plt.axhline(mean_exp_variance, color='r', linestyle='--')\n",
    "    plt.title(f'Explained Variance Distribution (Mean: {mean_exp_variance:.4f})')\n",
    "    plt.xlabel('Neuron Index')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predictions, correlations, exp_variances, mean_correlation, mean_exp_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c83a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, correlations, exp_variances, mean_correlation, mean_exp_variance = evaluate_model(\n",
    "    model=resnet50,         \n",
    "    eval_dataloader=eval_dataloader,  \n",
    "    y_val=y_val,          \n",
    "    device=device       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_extract = ['conv1', 'layer1', 'layer2', 'layer3', 'layer4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fa126",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = extract_features(resnet50, stimulus_train)\n",
    "features_val = extract_features(resnet50, stimulus_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ae593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_pcs_train, pretrained_pcs_val = apply_pca_to_features(\n",
    "            features_train, \n",
    "            features_val, \n",
    "            n_components=1000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa67242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting...\")\n",
    "layer_metrics = predict_neural_activity(pretrained_pcs_train, pretrained_pcs_val, y_train, y_val)\n",
    "\n",
    "filename = \"layer_metrics.json\"\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(layer_metrics, f, cls=NumpyEncoder, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
